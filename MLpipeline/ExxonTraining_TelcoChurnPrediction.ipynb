{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExxonTraining_TelcoChurnPrediction",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekapolc/exxon_training/blob/master/MLpipeline/ExxonTraining_TelcoChurnPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuIEwMRVAEMZ",
        "colab_type": "text"
      },
      "source": [
        "  # **INTRODUCTION - PREDICTING CHURN RATE**\n",
        "\n",
        "In this exercise, you will analyse customer data and predict behavior, in order to develop focused customer retention programs. The dataset contains data from over 7000 customers, including whether they have left within the past month -- a behavior called Churn.\n",
        "\n",
        "---\n",
        "There are three parts to this exercise :\n",
        "* **Part 1 - Data Cleaning** Formatting the data so that our predictive algorithm can understand it.\n",
        "* **Part 2 - Data Learning** Giving our algorithm the data to learn from,  discover hidden patterns, and make accurate predictions.\n",
        "* **Part 3 - Play with ROC** Finding the most suitable threshold for this task.\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iapj10MTSNXP",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjI5pmYg4pDB",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pprint\n",
        "import sklearn.model_selection\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random \n",
        "from google.colab import files \n",
        "from collections import OrderedDict\n",
        "\n",
        "#Classifiers\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Set seed\n",
        "seed = 18"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4AC8oB-7CRG",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Retrieval\n",
        "\n",
        "You can have a look at the dataset as a spreadsheet <a href=\"https://github.com/busyML/Predictiong-Customer-Churn/raw/master/Telco_Customer_Churn.xlsx\">here</a>. However, this exercise automatically downloads this spreadsheet to the Google Colab runtime for you, so you are not required to download it.\n",
        " \n",
        " Data Dictionary : <a href=\"https://www.kaggle.com/blastchar/telco-customer-churn\">https://www.kaggle.com/blastchar/telco-customer-churn</a>\n",
        "\n",
        "The following code downloads the spreadsheet and automatically converts it to a Pandas dataframe. What is Pandas? Think of it as Excel, only 100 times faster and for practical. We use it to manipulate huge spreadsheets of data in just a few seconds.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tly4hWA4SIVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We previously uploaded the data to this url and here we simply retrieving it.\n",
        "data_url= ('https://github.com/busyML/Predictiong-Customer-Churn/raw/master/Telco_Customer_Churn.xlsx')\n",
        "\n",
        "# Download the spreadsheet using Pandas's importing function.\n",
        "data=pd.read_excel(data_url)\n",
        "\n",
        "columnnames=data.columns \n",
        "print(columnnames) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGDaXyuC-mzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.set_index('CustomerID', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRhJn-6YAh2n",
        "colab_type": "text"
      },
      "source": [
        "#### Using the ***''.head\"*** command to explore data\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEHVGcBEAGGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiyX9Gg5Axoa",
        "colab_type": "text"
      },
      "source": [
        "# Part 1 - DATA CLEANING\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNqG_QgWLJlC",
        "colab_type": "text"
      },
      "source": [
        "###Todo#1 - Label Encoding\n",
        "\n",
        "Some columns contain binary values, meaning they are either one thing or not (for example: yes or no, true or false). To make these columns compatible with our algorithms, we can encode (represent) their values with **1** and **0**. Here we will set **Yes=1** and **No=0**. \n",
        "\n",
        "Let's encode these problem columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st4QGm-cRuM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Churn']=data['Churn'].apply(lambda x:1 if x=='Yes' else 0) \n",
        "data['Gender']=data['Gender'].apply(lambda x:1 if x=='Female' else 0) # Note here that unlike the other column, the keyword is \"Female\" not \"Yes\", however it is of course still binary class.\n",
        "data['Partner']=data['Partner'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "data['Dependents']=data['Dependents'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "data['PhoneService']=data['PhoneService'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "data['MultipleLines']=data['MultipleLines'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "data['OnlineSecurity']=data['OnlineSecurity'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "data['OnlineBackup']=data['OnlineBackup'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "# data['DeviceProtection']=data['DeviceProtection'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "\n",
        "## By the way, you can use sklearn to do this.\n",
        "le = LabelEncoder()\n",
        "le.fit(data['DeviceProtection'])\n",
        "data['DeviceProtection'] = le.transform(data['DeviceProtection'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUG2nOZNINFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYAKhVsWIjEE",
        "colab_type": "text"
      },
      "source": [
        "### Let's check other problem columns and fix them.\n",
        "There are other columns that have binary values. Explore the data more to see which other columns need to be encoded, and encode them in the same way as the previous code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpPPqr3NIds4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRHdocfoIIwQ",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "data['TechSupport']=data['TechSupport'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "data['StreamingTV']=data['StreamingTV'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "data['StreamingMovies']=data['StreamingMovies'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "data['PaperlessBilling']=data['PaperlessBilling'].apply(lambda x:1 if x=='Yes' else 0)\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLePOskeIpVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk5uvkZUUWKN",
        "colab_type": "text"
      },
      "source": [
        "###Todo#2 - One Hot Encoding\n",
        "\n",
        "Some column contains three or more possible text values. For instance, the column **['InternetService']**, which tells what type of internet service the customer is using, has the following possible outcomes:\n",
        "\n",
        "*   **Fiber optic**\n",
        "*   **DSL**\n",
        "*   **No Internet**\n",
        "\n",
        "To encode such a column as numerical values, we may use a technique called ***One Hot Encoding***. The trick is to **create** new columns for each possible outcome, each with binary values. So from the column **['InternetService']**, we are going to create three new columns : **['InternetService-FiberOptic']**, **['InternetService-DSL']**, and **['InternetService-NoInternet']**, each with values of either **1** or **0**. So if our customer has DSL Internet, as is the case with the customer ***7590-VHVEG***  in our first row, then our three new columns will look like this in the first row:\n",
        "\n",
        "*   **['InternetService-FiberOptic']** =  0\n",
        "*   **['InternetService-DSL']**=  1\n",
        "*   **['InternetService-NoInternet']**=  0\n",
        "\n",
        "\n",
        "And finally, don't forget to delete original column  **['InternetService']**.\n",
        "\n",
        "You can use **value_counts()** command in pandas for exploring data.\n",
        "\n",
        "\n",
        "Let's use one hot encoding to deal with it!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XnOR_8QXtIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_tmp = data.copy() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEAA-jRX0wnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in data['InternetService'].value_counts().keys(): \n",
        "      data[x]=data['InternetService'].apply(lambda d: 1 if d==x else 0)\n",
        "data.drop(columns=['InternetService'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDgx8nnzS_K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms5cA4-pTVeP",
        "colab_type": "text"
      },
      "source": [
        "### Let's check other problem columns and fix them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnHD0QibSz84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdqnW46SLPQK",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "for x in data['Contract'].value_counts().keys():\n",
        "    data[x]=data['Contract'].apply(lambda d: 1 if d==x else 0)\n",
        "data.drop(columns=['Contract'], inplace=True) \n",
        "    \n",
        "for x in data['PaymentMethod'].value_counts().keys():\n",
        "    data[x]=data['PaymentMethod'].apply(lambda d: 1 if d==x else 0)\n",
        "data.drop(columns=['PaymentMethod'], inplace=True) \n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svb3wGM4XfHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### By the way, you can use \"pd.get_dummies(data)\" to solve this problem. Yayyyy\n",
        "pd.get_dummies(data_tmp).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ufj_jloH-AA",
        "colab_type": "text"
      },
      "source": [
        "*italicized text*###Todo#3 - Splitting the Data\n",
        "\n",
        "Training : Testing = 80 : 20 \n",
        "\n",
        "random_state = seed (18)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--VRvvamIAZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data.drop(columns='Churn')\n",
        "y=data['Churn']\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "x_training, x_testing, y_training, y_testing = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRvpyLwX9vx",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "x_training, x_testing, y_training, y_testing = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSyF0SCsIFaH",
        "colab_type": "text"
      },
      "source": [
        "### Todo#4 - Mean Normalization\n",
        "\n",
        "While some columns already contain numerical values, they may have very different ranges. Some may range between 0-20 while others may be 100-2,000. Not ideal. \n",
        "\n",
        "To deal with this, let's pick out these columns that already have numerical data and perform **Mean Normalization** on them.  \n",
        "\n",
        "Equation :  X_norm = (X - mean) / std "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoI858m4ID5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_training_Tenure_mean = x_training['Tenure'].mean()\n",
        "x_training_Tenure_std = x_training['Tenure'].std()\n",
        "\n",
        "x_training['Tenure']=(x_training['Tenure']-x_training_Tenure_mean)/x_training_Tenure_std\n",
        "x_testing['Tenure']=(x_testing['Tenure']-x_training_Tenure_mean)/x_training_Tenure_std\n",
        "\n",
        "## You can use standard scaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_training['MonthlyCharges'].values.reshape(-1,1))\n",
        "x_training['MonthlyCharges'] = scaler.transform(x_training['MonthlyCharges'].values.reshape(-1,1)).reshape(-1)\n",
        "x_testing['MonthlyCharges'] = scaler.transform(x_testing['MonthlyCharges'].values.reshape(-1,1)).reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHU1UYW3oQk_",
        "colab_type": "text"
      },
      "source": [
        "### Let's check other problem columns and fix them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghd5zz-4ZBeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGaA7eq4IRsF",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "x_training_TotalCharges_mean = x_training['TotalCharges'].mean()\n",
        "x_training_TotalCharges_std = x_training['TotalCharges'].std()\n",
        "\n",
        "x_training['TotalCharges']=(x_training['TotalCharges']-x_training_TotalCharges_mean)/x_training_TotalCharges_std\n",
        "x_testing['TotalCharges']=(x_testing['TotalCharges']-x_training_TotalCharges_mean)/x_training_TotalCharges_std\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-GK9Mf93WgW",
        "colab_type": "text"
      },
      "source": [
        "### Todo#5 - Exploring Correlations\n",
        "Now that we have separated our target value (**y**) from the features (**x**), we can explore the correlation between them.\n",
        "\n",
        "We can use the \"x.corr(y)\" function for this, which outputs the correlation coefficient between the two columns x and y.\n",
        "\n",
        "A low correlation coefficient means that the column has low correlation with our target, **['Churn']**. We can consider columns with low correlation to be useless for predicting **['Churn']**.\n",
        "\n",
        "Now, let's explore the usefulness of each column. In this task, you will write some code to calculate correlation coefficients of all the columns, and sort them in descending order. We have provided code to help you plot a bar chart of each column's correlation coefficient.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0NjQAh7tg2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "corr = {}\n",
        "for columnname in x_training.columns: \n",
        "    corr[columnname] = \n",
        "corr = \n",
        "\n",
        "################################################################################\n",
        "name = [x[0] for x in corr]\n",
        "val = [x[1] for x in corr]\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.title('Customer Churn Predictors _ Correlations')\n",
        "plt.barh(range(len(corr)), val, color='b', align='center')\n",
        "plt.yticks(range(len(corr)), name)\n",
        "plt.xlabel('Importance Level')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSwmCM-6Ss0B",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "corr = {}\n",
        "for columnname in x_training.columns: \n",
        "    corr[columnname] = abs(x_training[columnname].corr(y_training))\n",
        "corr = sorted(corr.items(), key=lambda x: x[1], reverse=False)\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJBsgIVL2Wps",
        "colab_type": "text"
      },
      "source": [
        "### Todo#6 - Feature Importance from Decision Tree\n",
        "Using a Decision Tree can tell us which features are useful.\n",
        "\n",
        "In this task, you will train a <a href = https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html>decision tree</a> from sklearn on our data. Then, get the feature importance levels calculated by the decision tree, and sort them in descending order like you did with the correlation coefficients. Again, we have code for plotting the bar chart.\n",
        "\n",
        "Parameter Setup : n_estimator = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjKuNRgoUKJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "### Initialize model\n",
        "feature_importance_indicator = \n",
        "\n",
        "### Fit model\n",
        "feature_importance_indicator\n",
        "\n",
        "### Find Feature Importance\n",
        "features = \n",
        "importances = \n",
        "indices = np.argsort(importances)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.title('Customer Churn Predictors')\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Importance Level')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfrdlht9UQfF",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "        feature_importance_indicator=ExtraTreesClassifier(n_estimators = 100)\n",
        "        feature_importance_indicator.fit(x,y)\n",
        "        features = x.columns\n",
        "        importances = feature_importance_indicator.feature_importances_\n",
        "        indices = np.argsort(importances)\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL_Yy0U9398e",
        "colab_type": "text"
      },
      "source": [
        "### Todo#7  - Drop Useless Columns\n",
        "\n",
        "Consider the feature importances based on both the correlation and decision tree approaches. Which columns should you drop? Why? Please justify your answer.\n",
        "\n",
        "**Ans**\n",
        "\n",
        "Why do some columns have high correlation, but low importance according to the decision tree?\n",
        "\n",
        "**Ans**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP1up9lwkeAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Hint for above question\n",
        "\n",
        "corr = x_training.corr()\n",
        "plt.figure(figsize=(15,10))\n",
        "ax = sns.heatmap(\n",
        "    corr, \n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.diverging_palette(20, 220, n=200),\n",
        "    square=True, linewidths=.5\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right'\n",
        ");\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rF5rJPjn5qN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "          According to the heat map above, some columns are correlated with each other. For example, the columns from StreamingTV to FiberOptic have significantly high correlations among themselves. This means that, if the decision tree picks more than one of these columns, it wouldn't get much more information than it already knows. So it makes sense that the decision tree will only need to pick a subset of these columns.\n",
        "        </code>\n",
        "      </pre>\n",
        "# </details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSEaFLgd-Wam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "#### Drop columns\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UynHvf7uNfW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "x_training.drop(columns=['Gender','PhoneService','MultipleLines','OnlineBackup','DeviceProtection','StreamingTV','StreamingMovies'],inplace=True)\n",
        "x_testing.drop(columns=['Gender','PhoneService','MultipleLines','OnlineBackup','DeviceProtection','StreamingTV','StreamingMovies'],inplace=True)\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjJp6MpOAFLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's print our final data\n",
        "x_training.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4oxYL1OVckS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmPJuAXcNQBj",
        "colab_type": "text"
      },
      "source": [
        "#Part 2 - Data Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WtUwDprWnL8",
        "colab_type": "text"
      },
      "source": [
        "### Choosing The Evaluation Metric\n",
        "\n",
        "When a model makes a prediction, there are four possible outcomes: **True Positive**, **False Positive**, **True Negative**, and **False Negative**.\n",
        "\n",
        "* **True Positive**:  Predict 1, Actually 1\n",
        "* **False Positive**:  Predict 1, Actually 0\n",
        "* **True Negative** : Predict 0 , Actually 0\n",
        "* **False Negative**: Predict 0 , Actually 1\n",
        "\n",
        "These outcomes are commonly counted in the form of a matrix, called a **Confusion Matrix**. From this matrix, we can calculate three common evaluation metrics:\n",
        "\n",
        "1.   **Precision**: All correctly identified positives out of all positive predictions\n",
        "  - True Positive / (True Positive + False Positive)\n",
        "2. **Recall**: All positives covered by the predictions out of all positives\n",
        "  - True Positive / (True Positive + False Negative)\n",
        "3.  **F1 Score**: Harmonic mean of Precision and Recall\n",
        "\n",
        "For further reading : https://towardsdatascience.com/precision-vs-recall-386cf9f89488"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NYhil2BVf1v",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B44MehUvVFCD",
        "colab_type": "text"
      },
      "source": [
        "Between precision and recall, which evaluation metric do you think is more suitable for this task? Please justify your answer.\n",
        "\n",
        "**Ans**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn-RpLDUIhJO",
        "colab_type": "text"
      },
      "source": [
        "### Todo#8 - Creating, training and testing our algorithms \n",
        "\n",
        "Use **<a href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html>Logistic Regression model</a>** in Scikit-Learn to train a model with default parameters. Study the documentation for how to build and train (fit) the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqHu8v0dJGwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "### Build Model ###\n",
        "logistic_regression= \n",
        "\n",
        "### Fit Model ###\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xz7fA1mM2YS",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "        logistic_regression= LogisticRegression()\n",
        "        logistic_regression.fit(x_training,y_training)\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuPNyr4vLDd1",
        "colab_type": "text"
      },
      "source": [
        "### Todo#9 - Evaluation Model\n",
        "\n",
        "Our model is now trained! \n",
        "Next, we need to evaluate how well it can make predictions.\n",
        "\n",
        "In this task, you will implement a function to calculate the confusion matrix. From the true labels and predictions, count the occurrences of all four outcomes and return all the counts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOJ46StcLuqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusionCal(y_testing , pred):\n",
        "  ################################################################################\n",
        "  #                            WRITE YOUR CODE BELOW                             #\n",
        "  ################################################################################\n",
        "\n",
        "  #We initialize the following variables that help us count the number of True Positives, False Positives, etc.\n",
        "  TP=0\n",
        "  FP=0\n",
        "  TN=0\n",
        "  FN=0\n",
        "\n",
        "  #We use a loop to count the number of TN, TP, TN, FN. Each time we detech one, we add a '1' to the corresponding variable\n",
        "  for i in range(len(x_testing)):\n",
        "\n",
        "  \n",
        "  return TP, FP, TN, FN\n",
        "\n",
        "  ### By the way, you can do this in one line using sklearn.\n",
        "  ### confusion_matrix(y_testing, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCoR7oNULydB",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "TP=0\n",
        "FP=0\n",
        "TN=0\n",
        "FN=0\n",
        "\n",
        "for i in range(len(x_testing)):\n",
        "\n",
        "  if pred[i]==1 and y_testing.iloc[i]==1:\n",
        "                         TP=TP+1\n",
        "  if pred[i]==1 and y_testing.iloc[i]==0:\n",
        "                         FP=FP+1      \n",
        "  if pred[i]==0 and y_testing.iloc[i]==0:\n",
        "                         TN=TN+1    \n",
        "  if pred[i]==0 and y_testing.iloc[i]==1:\n",
        "                         FN=FN+1   \n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IduOHm8Es3hv",
        "colab": {}
      },
      "source": [
        "# predict test data and calculate TP, FP, TN and FN\n",
        "pred = logistic_regression.predict(x_testing)\n",
        "TP, FP, TN, FN = confusionCal(y_testing, pred)\n",
        "\n",
        "#Printing our results\n",
        "print (\"Logistic Regression\", \"True Positives:\",TP, \"False Positives:\",FP,\"True Negatives:\",TN , \"False Negatives:\", FN) \n",
        "\n",
        "\n",
        "#Calculating the 'Recall' metric with this simple formula\n",
        "log_recall=TP/(TP+FN)\n",
        "\n",
        "#Printing our the 'Recall' metric in %\n",
        "print(\"Logistic Regression Recall On Training Data:\", log_recall *100,'%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xomuq2oxALnk",
        "colab_type": "text"
      },
      "source": [
        "### Todo#10 - Play with Threshold\n",
        "\n",
        "In reality, our model is not trained to output either 0 or 1; it outputs a probability. The predict() function internally checks if this probability is more than a certain threshold, and outputs 1 if it is, 0 if not. By default, this threshold is 0.5.\n",
        "\n",
        "In this task, you will apply a different threshold value. You can get this probability from **predict_proba** function instead of **predict**. Assign all predictions with probabilities higher than this threshold to 1, and the others to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfZarJ3ZzuCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold = 0.45\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "#### using predict_proba and set threshold\n",
        "pred = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygwL_Wb8M_oj",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "pred = logistic_regression_opt.predict_proba(x_testing)\n",
        "pred = pred[:,1]\n",
        "pred[pred >= ratio] = 1\n",
        "pred[pred < ratio] = 0\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM0h2PA0JP7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate TP, FP, TN, FN and print the result\n",
        "TP, FP, TN, FN = confusionCal(y_testing, pred)\n",
        "\n",
        "print (\"Logistic Regression\", \"True Positives:\",TP, \"False Positives:\",FP,\"True Negatives:\",TN , \"False Negatives:\", FN) \n",
        "\n",
        "log_recall=TP/(TP+FN)\n",
        "\n",
        "print(\"Logistic Regression Recall On Training Data:\", log_recall *100,'%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmnNU7cZPy0c",
        "colab_type": "text"
      },
      "source": [
        "# Part 3 - Playing with ROC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6SMxRH9KqED",
        "colab_type": "text"
      },
      "source": [
        "### Todo#11 - Exploring our model using ROC\n",
        "\n",
        "After exploring different thresholds, we will explore our model in deeper depth by its <a href=https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html>Receiver Operating Characteristic (ROC)</a> curve. In this task, you will be working with two models with slightly different parameters. Take the probability outputs from both models, and use the roc_curve function to calculate the false positive rates (FPR) and true positive rates (TPR)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuwgjDrNOCVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistic_regression_line1 = LogisticRegression(max_iter=1, class_weight={1:0.9, 0:0.1})\n",
        "logistic_regression_line1.fit(x_training,y_training)\n",
        "\n",
        "logistic_regression_line2= LogisticRegression(max_iter=1, class_weight={1:0.99, 0:0.01})\n",
        "logistic_regression_line2.fit(x_training,y_training)\n",
        "\n",
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "#### Predict and Use roc_curve function to get fpr and tpr of prediction of line1 model\n",
        "pred = \n",
        "fpr, tpr, thresholds = \n",
        "roc_auc = \n",
        "\n",
        "#### Predict and Use roc_curve function to get fpr and tpr of prediction of line2 model\n",
        "pred2 = \n",
        "fpr2, tpr2, thresholds = \n",
        "roc_auc2 = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MHzSmp5OGR8",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "\n",
        "\n",
        "##### Predict and Use roc_curve function to get fpr and tpr of prediction of line1 model\n",
        "\n",
        "pred = logistic_regression_line1.predict_proba(x_testing)\n",
        "fpr, tpr, thresholds = roc_curve(  y_testing.values, pred[:,1] )\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "##### Predict and Use roc_curve function to get fpr and tpr of prediction of line2 model\n",
        "\n",
        "pred2 = logistic_regression_line2.predict_proba(x_testing)\n",
        "fpr2, tpr2, thresholds = roc_curve(  y_testing.values, pred2[:,1] )\n",
        "roc_auc2 = auc(fpr2, tpr2)\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBMX1d_6AfTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot(fpr2, tpr2, lw=1, label='ROC curve (area = %0.2f)' % roc_auc2)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvdyVTnv12E8",
        "colab_type": "text"
      },
      "source": [
        "According to the graph above, which line (orange or blue) do you think is better? \n",
        "\n",
        "**Ans**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsHrTcIInXz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### If we would like to set FPR as 0.1\n",
        "\n",
        "print(\"With the condition, threshold is \",thresholds[np.argmin(abs(fpr-0.1))])\n",
        "print(\"TPR : \",tpr[np.argmin(abs(fpr-0.1))])\n",
        "print(\"FPR : \",fpr[np.argmin(abs(fpr-0.1))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD9Vr8cknx46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### If we would like to set TPR as 0.8\n",
        "\n",
        "print(\"With the condition, threshold is \",thresholds[np.argmin(abs(tpr-0.8))])\n",
        "print(\"TPR : \",tpr[np.argmin(abs(tpr-0.8))])\n",
        "print(\"FPR : \",fpr[np.argmin(abs(tpr-0.8))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWw1EHWpEdsg",
        "colab_type": "text"
      },
      "source": [
        "###Todo#12 - Model Optimization\n",
        "\n",
        "You may have noticed that the data is imbalanced. There are significantly more 0 labels than 1 labels. One possible workaround for this issue is to set *class weight* parameter in the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7XynOvhEeJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "#we initialize a class weights for our two labels : 1 (churned) and 0 (churned) at 70-30\n",
        "\n",
        "class_weights ={1: 0.70, 0: 0.30}\n",
        "\n",
        "### we create a new logistic regression model optimized for a better recall and retrain it on our data\n",
        "logistic_regression_opt = \n",
        "### Fit model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s09vcZJLG6j6",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "class_weights ={1: 0.70, 0: 0.30}\n",
        "\n",
        "logistic_regression_opt= LogisticRegression(class_weight=class_weights)\n",
        "logistic_regression_opt.fit(x_training,y_training)\n",
        "\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpS9kaCpEeUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "#Re-evaluating the model on the 70-30 split.\n",
        "\n",
        "pred = \n",
        "TP, FP, TN, FN = \n",
        "\n",
        "print (\"Logistic Regression\", \"True Positives:\",TP, \"False Positives:\",FP,\"True Negatives:\",TN , \"False Negatives:\", FN) \n",
        "\n",
        "log_recall=TP/(TP+FN)\n",
        "\n",
        "print(\"Logistic Regression Recall On Training Data:\", log_recall *100,'%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw-SwAvKHJRl",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "\n",
        "pred = logistic_regression_opt.predict(x_testing)\n",
        "TP, FP, TN, FN = confusionCal(pred, y_testing)\n",
        "\n",
        "print (\"Logistic Regression\", \"True Positives:\",TP, \"False Positives:\",FP,\"True Negatives:\",TN , \"False Negatives:\", FN) \n",
        "\n",
        "log_recall=TP/(TP+FN)\n",
        "\n",
        "print(\"Logistic Regression Recall On Training Data:\", log_recall *100,'%')\n",
        "\n",
        "\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goL0V9iZEeRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "#Update the weights to 85-15%\n",
        "class_weights = {1: 0.85, 0: 0.15}\n",
        "\n",
        "### Retrain the algorithm\n",
        "logistic_regression_opt = \n",
        "### Fit model \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoJUr7FaHX49",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "class_weights ={1: 0.85, 0: 0.15}\n",
        "\n",
        "logistic_regression_opt= LogisticRegression(class_weight=class_weights)\n",
        "logistic_regression_opt.fit(x_training,y_training)\n",
        "\n",
        "\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44225PqvEeOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "#Re-evaluating the model on the 85-15 split.\n",
        "pred = logistic_regression_opt.predict(x_testing)\n",
        "TP, FP, TN, FN = confusionCal(y_testing, pred)\n",
        "print (\"Logistic Regression\", \"True Positives:\",TP, \"False Positives:\",FP,\"True Negatives:\",TN , \"False Negatives:\", FN) \n",
        "\n",
        "log_recall=TP/(TP+FN)\n",
        "print(\"Logistic Regression Recall On Training Data:\", log_recall *100,'%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykruhb9pHjka",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "pred = logistic_regression_opt.predict(x_testing)\n",
        "TP, FP, TN, FN = confusionCal(pred, y_testing)\n",
        "\n",
        "print (\"Logistic Regression\", \"True Positives:\",TP, \"False Positives:\",FP,\"True Negatives:\",TN , \"False Negatives:\", FN) \n",
        "\n",
        "log_recall=TP/(TP+FN)\n",
        "\n",
        "print(\"Logistic Regression Recall On Training Data:\", log_recall *100,'%') **bold text**\n",
        "\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYpdHfN6DYLb",
        "colab_type": "text"
      },
      "source": [
        "As you have seen previously, a model's prediction falls into one of these four outcomes: TP,  FP, TN and FN.\n",
        "\n",
        "You may have also seen the values TPR and FPR. These rates are actually related to our four outcomes. TPR represents the number of TP out of all correct samples. On the other hand, FPR represents number of FP out of all incorrect samples. \n",
        "\n",
        "Adjusting the threshold affects TPR and FPR. Choosing the most suitable threshold therefore depends on the task, as each real-world task may have different operational costs for TP, FP, FN and TN. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erNwXlWtRO0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = logistic_regression_opt.predict_proba(x_testing)\n",
        "\n",
        "b_y = np.linspace(0, 1.05)\n",
        "b_x = 1 - b_y\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(  y_testing.values, pred[:,1] )\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.plot(b_x, b_y)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgOBhhTbfLSW",
        "colab_type": "text"
      },
      "source": [
        "The blue line in this graph represents where a miss (FN) is as bad or costly as a false alarm (FP). The point where it intersects with the ROC curve (orange) is called Equal Error Rate (EER). \n",
        "\n",
        "The following code calculates the threshold most suitable for this condition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8n_5_c4aCEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Calculate Miss\n",
        "miss = 1 - tpr\n",
        "print(\"With the condition, threshold is \",thresholds[(np.nanargmin(abs(miss - fpr)))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIvN8tNeysj8",
        "colab_type": "text"
      },
      "source": [
        "###Todo#13 - Tuning on task (2)\n",
        "\n",
        "Let's think about how we can prevent churn.\n",
        "\n",
        "One way is to give promotions to potential churn customers.\n",
        "\n",
        "Let's say we give out coupons to customers that will reduce the price by 5 USD.\n",
        "The average payment for a customer is 65 USD.\n",
        "\n",
        "A false alarm would cost us 5 USD. (why?)\n",
        "A correct churn prediction would give us 60 USD.\n",
        "\n",
        "Can you draw a graph and find the threshold that matches with the condition?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwxJIxEmysYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "################################################################################\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(b_x, b_y)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLmzFQ4YisoT",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "pred = logistic_regression_opt.predict_proba(x_testing)\n",
        "\n",
        "b_y = np.linspace(0, 1.00)\n",
        "b_x = (1-b_y)/12\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(  y_testing.values, pred[:,1], drop_intermediate=False )\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsE8s3ZZih-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Calculate Miss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYHRMLPEiy3T",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "miss = (1 - tpr)/13\n",
        "print(\"With the condition, threshold is \",thresholds[(np.nanargmin(abs(miss - fpr)))])\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhgvQk1uzGYs",
        "colab_type": "text"
      },
      "source": [
        "In this problem, we also know the current monthly payment of each customer, so we can actually have different thresholds for each customer. How would we accomplish this? What would be the criterion to intervene? This is left as a thought excercise :)"
      ]
    }
  ]
}