{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExxonTraining2_Classification_Shap_Calibration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekapolc/exxon_training/blob/master/explainability/ExxonTraining2_Classification_Shap_Calibration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDjq8CkxrDo-",
        "colab_type": "text"
      },
      "source": [
        "## Install these packages before starting this lab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM0db_qhrIB_",
        "colab_type": "code",
        "outputId": "8ac681c9-2047-4197-e42e-0de4add3faaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!pip install xlrd\n",
        "!pip install pydot\n",
        "!pip install pyparsing\n",
        "!apt-get install graphviz\n",
        "!pip install graphviz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt-3VgjrrV-n",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyTdWKfKqpaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from xgboost import XGBClassifier, plot_tree, plot_importance\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Js8nP9DAj0H",
        "colab_type": "code",
        "outputId": "74ad8e14-136d-4f2f-d8b3-8c95c6439778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.version.version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.16.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-mz16DaqpaL",
        "colab_type": "text"
      },
      "source": [
        "# XGboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP_s7QJXxB0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GATNe5MvqpaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load our pre-processed data\n",
        "PATH = '/content/'\n",
        "df = pd.read_csv(PATH+'data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rts-EKZMqpaO",
        "colab_type": "code",
        "outputId": "5b555745-e3e5-4e51-b696-c89abca49d90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4591, 19)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SerialNumber</th>\n",
              "      <th>Leave</th>\n",
              "      <th>ActionYear</th>\n",
              "      <th>WorkDurationYear</th>\n",
              "      <th>CountLoan</th>\n",
              "      <th>Avg_MonthPerLoan</th>\n",
              "      <th>HireType</th>\n",
              "      <th>HireSourceGroup</th>\n",
              "      <th>WorkDurationYear.1</th>\n",
              "      <th>Avg_TotalAbsensePerYear</th>\n",
              "      <th>Avg_NumDaysPerAbsense</th>\n",
              "      <th>TotalEduAllowance</th>\n",
              "      <th>NumYear_SinceLastEduAllowance</th>\n",
              "      <th>TotalEduAttend</th>\n",
              "      <th>EduBranch_CHEM</th>\n",
              "      <th>EduBranch_Finance</th>\n",
              "      <th>EduBranch_Languages</th>\n",
              "      <th>Max_EduInstituteGroup</th>\n",
              "      <th>NumYear_SinceLastEdu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2000</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2000</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>UNIV</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2000</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2000</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>SCHL</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2000</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SerialNumber  Leave  ...  Max_EduInstituteGroup  NumYear_SinceLastEdu\n",
              "0             4    1.0  ...                Unknown                  41.0\n",
              "1             5    1.0  ...                   UNIV                  40.0\n",
              "2             6    1.0  ...                Unknown                  47.0\n",
              "3             7    1.0  ...                   SCHL                  39.0\n",
              "4            10    1.0  ...                Unknown                  38.0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2hDPD9jqpaS",
        "colab_type": "code",
        "outputId": "bdb406da-3a0d-48b9-a814-c771566c9a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# Print columns in dataframe\n",
        "print(df.columns.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SerialNumber' 'Leave' 'ActionYear' 'WorkDurationYear' 'CountLoan'\n",
            " 'Avg_MonthPerLoan' 'HireType' 'HireSourceGroup' 'WorkDurationYear.1'\n",
            " 'Avg_TotalAbsensePerYear' 'Avg_NumDaysPerAbsense' 'TotalEduAllowance'\n",
            " 'NumYear_SinceLastEduAllowance' 'TotalEduAttend' 'EduBranch_CHEM'\n",
            " 'EduBranch_Finance' 'EduBranch_Languages' 'Max_EduInstituteGroup'\n",
            " 'NumYear_SinceLastEdu']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT7rqPkQoaQM",
        "colab_type": "text"
      },
      "source": [
        "### Todo#1 - Create One-hot features\n",
        "In the previous lab, we have learned how to deal with categorical features. This lab also contains categorical features, and we will be dealing with them.\n",
        "\n",
        "#### Question : Explore data and find out which features are categorical.\n",
        "\n",
        "#### Answer : \n",
        "\n",
        "#### Instructions : Write code to transform the categorical features to one-hot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu-XU6MLqpaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "# Create one-hot feature columns. We will drop the original columns afterwards.\n",
        "\n",
        "\n",
        "# Concatenate the new columns to the dataframe\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGGkRCOqp3tU",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "    <summary>SOLUTION HERE!</summary>\n",
        "      <pre>\n",
        "        <code>\n",
        "dfEduInstituteGroup = pd.get_dummies(df['Max_EduInstituteGroup'], prefix='Max_EduInstituteGroup')\n",
        "dfHireTypeGroup = pd.get_dummies(df['HireType'], prefix='HireType')\n",
        "dfHireSourceGroup = pd.get_dummies(df['HireSourceGroup'], prefix='HireSourceGroup')\n",
        "\n",
        "df = pd.concat([df, dfEduInstituteGroup, dfHireTypeGroup, dfHireSourceGroup], axis=1)\n",
        "        </code>\n",
        "      </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm_1NMVoqpaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDyG-ZFDqpab",
        "colab_type": "text"
      },
      "source": [
        "### Todo#2 - Split Train and Test\n",
        "\n",
        "Usually, time series data will be splitted to train and test set according to time period, to avoid the look-ahead bias -- taking data from the \"future\" which we are not supposed to know yet. To simulate a production environment, the test set should be the most recent part of data. \n",
        "\n",
        "We will try to use xgboost model to predict whether an employee is still working for the company after 2017. So, we divide our train and test set using ActionYear 2017.\n",
        "\n",
        "#### Instructions : Split the data into `df_train` for training and `df_test` for testing. Use data *before* 2017 as the train set, and the rest (from 2017 and after) as the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z56tfA08qpab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "### Split train and test data using \"ActionYear\" feature\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "masL3WXMqrt7",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "df_train = df[ df['ActionYear'] < 2017]\n",
        "df_test = df[df['ActionYear'] >= 2017]\n",
        "\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUjPgaRXqpae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_train.shape, df_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDT5Z9AKrR2y",
        "colab_type": "text"
      },
      "source": [
        "###Todo#3 - Drop irrelevant columns and create labels\n",
        "\n",
        "#### Question : Besides the original categorical columns, which columns do you think are not necessary for your model?\n",
        "\n",
        "#### Answer :\n",
        "\n",
        "#### Instructions : Drop all unnecessary columns, including the categorical columns from Todo#1 and the columns you answered in this question. Also, put the labels (did the employee leave the company or not) into variables `df_train_label` and  `df_test_label`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m1kLuJ0qpah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "### Drop irrelevant columns and build label in df_train \n",
        "\n",
        "\n",
        "### Drop irrelevant columns and build label in df_test \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOVenllqrge8",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "df_train_variable = df_train.drop(['SerialNumber','ActionYear','Leave','Max_EduInstituteGroup','HireType','HireSourceGroup'],axis=1)\n",
        "df_train_label = df_train['Leave']\n",
        "\n",
        "df_test_variable = df_test.drop(['SerialNumber','ActionYear','Leave','Max_EduInstituteGroup','HireType','HireSourceGroup'],axis=1)\n",
        "df_test_label = df_test['Leave']\n",
        "\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq7NkOzdqpal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Just change name variable\n",
        "X_train, X_test, y_train, y_test = df_train_variable, df_test_variable, df_train_label, df_test_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt8THQaOqpao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6v_Fdu7qpas",
        "colab_type": "text"
      },
      "source": [
        "### Todo#4 - Build XGBoost model\n",
        "\n",
        "Here, we will create our xgboost classifier that will classify 2 classes -- whether each employee will leave the company by the end of 2017 or not -- using some pre-defined hyperparameters. Note that these hyperparameters should be tuned for each different task and dataset.\n",
        "\n",
        "Full details of each hyperparameter can be found in [XGBoost Docs](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster)\n",
        "\n",
        "#### Instructions : Define your model and set its parameters according to the following:\n",
        "- n_jobs =16\n",
        "- n_estimators=400\n",
        "- max_depth=4\n",
        "- objective=\"binary:logistic\"\n",
        "- learning_rate=0.07\n",
        "- subsample=0.9\n",
        "- min_child_weight=6\n",
        "- colsample_bytree=.9\n",
        "- scale_pos_weight=0.8\n",
        "- gamma=8\n",
        "- reg_alpha=6\n",
        "- reg_lambda=1.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwMu2kBvqpat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "# Define our model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krZRcpgxs8qH",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "model = XGBClassifier(    \n",
        "    n_jobs=-1,\n",
        "    n_estimators=400,\n",
        "    max_depth=4,\n",
        "    objective=\"binary:logistic\",\n",
        "    learning_rate=0.07, \n",
        "    subsample=0.9,\n",
        "    min_child_weight=6,\n",
        "    colsample_bytree=.9,\n",
        "    scale_pos_weight=0.8,\n",
        "    gamma=8,\n",
        "    reg_alpha=6,\n",
        "    reg_lambda=1.3)\n",
        "\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI4zhyelqpav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "# Train the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEzu0MnxmCRL",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "<summary>SOLUTION HERE!</summary>\n",
        "<pre>\n",
        "<code>\n",
        "model.fit(X_train, y_train)\n",
        "print(model)\n",
        "</code>\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilUvkq09qpax",
        "colab_type": "text"
      },
      "source": [
        "#### Predict test labels for model evaluation\n",
        "Just like the previous lab, by calling predict_proba(input_data), the model will output the probabilities of each output class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RByZEalFqpax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWpsXpiSqpa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict test label for model evaluation\n",
        "# Since we only have 2 classes, 0 and 1, we will use predict_proba(X_test)[:,1] as probability of employees levaing the company\n",
        "y_pred = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "### set temp variable to use in later cells.\n",
        "y_test_model1 = y_test\n",
        "y_predictions_model1 = y_pred\n",
        "\n",
        "# Round the predicted probabilities to get predicted labels\n",
        "predictions = [np.round(value) for value in y_pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUPz4VHiqpa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCwOwYpZqpa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EJvb0utqpa-",
        "colab_type": "text"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1KUWrPSqpa-",
        "colab_type": "text"
      },
      "source": [
        "### Todo#5 - Target Encoding\n",
        "When dealing with columns of categorical features (e.g. user group is either 1, 2, or 3) we usually create new one-hot feature columns for all possible categories which will have value '1' in the column that each of them belongs to, and '0' otherwise. However, by creating new one-hot feature columns for every category, we will end up with a lot of columns, which might be difficult for the model to learn.\n",
        "\n",
        "In this section, we will encode those categorical features into a new columns that will be easier to be learned by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sv6LAK0qpa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_noise(series, noise_level):\n",
        "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
        "\n",
        "\n",
        "def target_encode(trn_series=None,\n",
        "                  tst_series=None,\n",
        "                  target=None,\n",
        "                  min_samples_leaf=1,\n",
        "                  smoothing=1,\n",
        "                  noise_level=0):\n",
        "    \"\"\"\n",
        "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
        "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
        "    trn_series : training categorical feature as a pd.Series\n",
        "    tst_series : test categorical feature as a pd.Series\n",
        "    target : target data as a pd.Series\n",
        "    min_samples_leaf (int) : minimum samples to take category average into account\n",
        "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
        "    \"\"\"\n",
        "    assert len(trn_series) == len(target)\n",
        "    assert trn_series.name == tst_series.name\n",
        "    temp = pd.concat([trn_series, target], axis=1)\n",
        "    # Compute target mean\n",
        "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
        "    \n",
        "    # Compute smoothing\n",
        "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
        "    \n",
        "    # Apply average function to all target data\n",
        "    prior = target.mean()\n",
        "    \n",
        "    # The bigger the count the less full_avg is taken into account\n",
        "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
        "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
        "    \n",
        "    # Apply averages to trn and tst series\n",
        "    ft_trn_series = pd.merge(\n",
        "        trn_series.to_frame(trn_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=trn_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_trn_series.index = trn_series.index\n",
        "\n",
        "    ft_tst_series = pd.merge(\n",
        "        tst_series.to_frame(tst_series.name),\n",
        "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
        "        on=tst_series.name,\n",
        "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
        "    # pd.merge does not keep the index so restore it\n",
        "    ft_tst_series.index = tst_series.index\n",
        "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ1eVab2sEX4",
        "colab_type": "text"
      },
      "source": [
        "### Train new model with target encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sanjR0gdqpbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load our pre-processed data\n",
        "df = pd.read_csv(PATH+'data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psi7Zv74qpbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHYzDlblJK8G",
        "colab_type": "text"
      },
      "source": [
        "#### Instructions : Write code to transform the categorical features to one-hot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si0bO1HHqpbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "# Create one-hot feature columns for Max_EduInstituteGroup, HireType, HireSourceGroup\n",
        "\n",
        "\n",
        "# Concat the new columns to the dataframe\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAPZh4jat9bn",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "  <summary>SOLUTION HERE!</summary>\n",
        "  <pre>\n",
        "    <code>\n",
        "dfEduInstituteGroup = pd.get_dummies(df['Max_EduInstituteGroup'], prefix='Max_EduInstituteGroup')\n",
        "dfHireTypeGroup = pd.get_dummies(df['HireType'], prefix='HireType')\n",
        "dfHireSourceGroup = pd.get_dummies(df['HireSourceGroup'], prefix='HireSourceGroup')\n",
        "\n",
        "df = pd.concat([df, dfEduInstituteGroup,dfHireTypeGroup,dfHireSourceGroup], axis=1)\n",
        "      </code>\n",
        "  </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFbb-DRWqpbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split train/test \n",
        "df_train = df[ df['ActionYear'] < 2017]\n",
        "df_train.shape\n",
        "\n",
        "df_test = df[ df['ActionYear'] >= 2017]\n",
        "df_test.shape\n",
        "\n",
        "df_train_variable = df_train.drop(['SerialNumber','ActionYear','Leave'],axis=1)\n",
        "df_train_label = df_train['Leave']\n",
        "\n",
        "df_test_variable = df_test.drop(['SerialNumber','ActionYear','Leave'],axis=1)\n",
        "df_test_label = df_test['Leave']\n",
        "\n",
        "X_train, X_test, y_train, y_test = df_train_variable, df_test_variable, df_train_label, df_test_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTLh2uUpqpbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Target encode these categorical features in our data\n",
        "col_names_cat = ['HireType', 'HireSourceGroup', 'Max_EduInstituteGroup']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCxC-9Awqpb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enocode categorical features\n",
        "for f in col_names_cat:\n",
        "    X_train[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
        "                                              trn_series=X_train[f],\n",
        "                                              tst_series=X_test[f],\n",
        "                                              target=y_train,\n",
        "                                              min_samples_leaf=200,\n",
        "                                              smoothing=10,\n",
        "                                              noise_level=0\n",
        "                                              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdsSyeULqpb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.columns.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-7GwQJqpb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample encoded values\n",
        "X_train[:10][['HireType', 'HireType_avg', 'HireSourceGroup', 'HireSourceGroup_avg', 'Max_EduInstituteGroup', 'Max_EduInstituteGroup_avg']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjHE8t7XupJQ",
        "colab_type": "text"
      },
      "source": [
        "#### Question : Looking at the cell above, what do you think about encoding these columns? Does it make sense to do? Give your explanation.\n",
        "\n",
        "#### Answer : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alIlKZRrqpcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop the original features\n",
        "X_train = X_train.drop(['Max_EduInstituteGroup','HireType','HireSourceGroup'], axis=1)\n",
        "X_test = X_test.drop(['Max_EduInstituteGroup','HireType','HireSourceGroup'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIupBAD9JvHk",
        "colab_type": "text"
      },
      "source": [
        "#### Instructions : Define the model with the same parameters as Todo#4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7-ZHCTTqpcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "#                            WRITE YOUR CODE BELOW                             #\n",
        "################################################################################\n",
        "\n",
        "# Define model same as previous model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGGQZ5fIuhFn",
        "colab_type": "text"
      },
      "source": [
        "<details>\n",
        "  <summary>SOLUTION HERE!</summary>\n",
        "  <pre>\n",
        "    <code>\n",
        "model = XGBClassifier(    \n",
        "    n_jobs=-1,\n",
        "    n_estimators=400,\n",
        "    max_depth=4,\n",
        "    objective=\"binary:logistic\",\n",
        "    learning_rate=0.07, \n",
        "    subsample=0.9,\n",
        "    min_child_weight=6,\n",
        "    colsample_bytree=.9,\n",
        "    scale_pos_weight=0.8,\n",
        "    gamma=8,\n",
        "    reg_alpha=6,\n",
        "    reg_lambda=1.3)\n",
        "      </code>\n",
        "  </pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il_SNcN3qpcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgezbqSyqpcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions for test data\n",
        "y_pred_all = model.predict_proba(X_test)\n",
        "y_pred = y_pred_all[:,1]\n",
        "\n",
        "# set tmp for using in roc \n",
        "y_test_model2 = y_test\n",
        "y_predictions_model2 = y_pred\n",
        "\n",
        "predictions = [np.round(value) for value in y_pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGbgiK1fqpcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoA4BVkpYWlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Model 1 (Not-Encode)\n",
        "fpr1, tpr1, thresholds = roc_curve(  y_test_model1, y_predictions_model1 )\n",
        "roc_auc1 = auc(fpr1, tpr1)\n",
        "\n",
        "### Model 2 (Encode)\n",
        "fpr2, tpr2, thresholds = roc_curve(  y_test_model2, y_predictions_model2 )\n",
        "roc_auc2 = auc(fpr2, tpr2)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(fpr1, tpr1, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc1) ## Orange Line\n",
        "plt.plot(fpr2, tpr2, lw=1, label='ROC curve (area = %0.2f)' % roc_auc2) ## Blue Line\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMW_IDKswuZ9",
        "colab_type": "text"
      },
      "source": [
        "### Todo#6 - Visualize our graph model\n",
        "XGBoost is a gradient boosting model. With graphviz library, you can visually find out how your model works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL3LDcOuqpcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View tree\n",
        "# Because graphviz seams to have some resolution problem with pyplot and jupyter, we have to use to trick below to get a readable graph\n",
        "# fig = plt.gcf()\n",
        "# fig.set_size_inches(10, 10)\n",
        "fig, ax = plt.subplots(figsize=(10, 10), dpi=200)\n",
        "\n",
        "# Plot the n-th tree of the model. Note that the model consists of many tress (as defined when creating the model)\n",
        "plot_tree(model, num_trees=0,  ax=ax)\n",
        "# fig.savefig('tree.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbMlleQLqpca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot how many times each feature is used as node in the tree\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "plot_importance(model, ax=ax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCX61v_I6CZy",
        "colab_type": "text"
      },
      "source": [
        "#### Question : What do you think about the insight and information from the above cells? Does it make sense, and how?\n",
        "#### Answer : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exv2UIN-83ot",
        "colab_type": "text"
      },
      "source": [
        "### Todo#7 - Deeply explore your  model with Shap\n",
        "\n",
        "<a href =\"https://github.com/slundberg/shap\">SHAP</a> (SHapley Additive exPlanations) is a unified approach to explaining the output of any machine learning model. SHAP connects game theory with local explanations, uniting several previous methods and representing the only possible consistent and locally accurate additive feature attribution method based on expectations.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/slundberg/shap/master/docs/artwork/shap_diagram.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rw8mmAtMfvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPQmfLLTGwrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "explainer = shap.TreeExplainer(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24GkNVKIcQQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shap_values = explainer.shap_values(X_test)\n",
        "print('Expected Value:', explainer.expected_value)\n",
        "pd.DataFrame(shap_values).head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCwOO3kNcSKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Google Colab needs shap.initjs() in every cell where there is a visualization.\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, \n",
        "                shap_values[0,:], X_test.iloc[0,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhpvb-M8jUXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, \n",
        "                shap_values, X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMwOsWQuvNeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shap.summary_plot(shap_values,\n",
        "                  X_test, plot_type=\"bar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0SD7xEhvQRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shap.summary_plot(shap_values, X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-oWuH2cvSHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shap.dependence_plot(ind='WorkDurationYear', interaction_index='WorkDurationYear',\n",
        "                     shap_values=shap_values, \n",
        "                     features=X_test,  \n",
        "                     display_features=X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-8lQV4vUN1",
        "colab_type": "text"
      },
      "source": [
        "#### Question : As you explore your model using Shap, is there anything that makes you interested? Try to change your model parameter and see the changed shap plot.\n",
        "#### Answer : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHP0cd6NpyNR",
        "colab_type": "text"
      },
      "source": [
        "### Todo#8 - Calibration with Ensemble\n",
        "Predicted probabilities that match the expected distribution of probabilities for each class are said to be *calibrated*. However, not all machine learning models are capable of predicting calibrated probabilities. There are methods to both diagnose how calibrated the predicted probabilities are, and how to better calibrate the predicted probabilities with the observed distribution of each class. Often, this can lead to better quality predictions, depending on how the skill of the model is evaluated.\n",
        "\n",
        "Ensemble techniques can help us calibrate our model.\n",
        "\n",
        "For more examples on calibration see <a href=\"https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/\">here for more details</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwrQjskJp0Ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define bins function\n",
        "def buildBins(y_pred):\n",
        "  count_bin = [0]*10\n",
        "  total_bin = [0]*10\n",
        "  for i in range(len(y_pred)):\n",
        "    total_bin[(int(y_pred[i][1]*100//10))]+=1\n",
        "    if(y_test.values[i]==1 and y_pred[i][1]>=0.5):\n",
        "      count_bin[(int(y_pred[i][1]*100//10))]+=1\n",
        "  return np.array(count_bin), np.array(total_bin)\n",
        "\n",
        "def plotCalibrate(count_bin, total_bin):\n",
        "  \n",
        "  total_bin[total_bin==0]=1\n",
        "  ratio_bin = count_bin / total_bin\n",
        "  fig, ax = plt.subplots(figsize=(15,9), )\n",
        "  lm = sns.barplot(np.arange(10),ratio_bin,palette=\"Blues_d\")\n",
        "  sns.lineplot(np.arange(10), np.arange(10)/10)\n",
        "  axes = lm.axes\n",
        "  axes.set_ylim(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3jupYpPK1IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cal bin for simple model\n",
        "count_bin, total_bin = buildBins(y_pred_all.copy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUSNjj7n4Edt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot number of data in each bins\n",
        "plt.figure(figsize=(15,9))\n",
        "sns.barplot(np.arange(10),total_bin, facecolor=(0.9, 0.4, 0.4, 0.5),saturation=0.9)\n",
        "sns.barplot(np.arange(10),count_bin,facecolor=(0.1, 0.6, 0.7, 0.9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7lnlI3Pp4Fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot calibrate on simple model\n",
        "plotCalibrate(count_bin, total_bin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSTQVtRa2UaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 10 folds and 10 model (ensemble)\n",
        "kf = KFold(n_splits=10)\n",
        "model_set = {}\n",
        "y_pred_ensemble_all = []\n",
        "tmp = 0\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "  model = XGBClassifier(    \n",
        "          n_jobs=16,\n",
        "          n_estimators=400,\n",
        "          max_depth=4,\n",
        "          objective=\"binary:logistic\",\n",
        "          learning_rate=0.07, \n",
        "          subsample=0.9,\n",
        "          min_child_weight=6,\n",
        "          colsample_bytree=.9,\n",
        "          scale_pos_weight=0.8,\n",
        "          gamma=8,\n",
        "          reg_alpha=6,\n",
        "          reg_lambda=1.3)\n",
        "  model_set[tmp] = model\n",
        "  X_train_tmp, _ = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "  y_train_tmp, _ = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "  model.fit(X_train_tmp, y_train_tmp)\n",
        "  y_pred_ensemble_all.append(model.predict_proba(X_test))\n",
        "  tmp+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tmjnbjR4Cwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_ensemble = np.array(y_pred_ensemble_all).mean(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "857MPoFX4mTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_bin_ensemble, total_bin_ensemble = buildBins(y_pred_ensemble.copy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPWDg5wB4qLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15,9))\n",
        "sns.barplot(np.arange(10),total_bin_ensemble, facecolor=(0.9, 0.4, 0.4, 0.5),saturation=0.9)\n",
        "sns.barplot(np.arange(10),count_bin_ensemble,facecolor=(0.1, 0.6, 0.7, 0.9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1n3oyjF4scq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotCalibrate(count_bin_ensemble,total_bin_ensemble)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPkjptyW0pKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calGap(total, count):\n",
        "  total[total==0]=1\n",
        "  ratio = count / total\n",
        "  return abs(ratio - np.array([0.5,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95])).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygmyz_xL0qBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Simple Model Confidence Error : \",calGap(total_bin, count_bin))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWnUHGW71y-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Ensemble Model Confidence Error \",calGap(total_bin_ensemble, count_bin_ensemble))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNKCRB-jMM16",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}